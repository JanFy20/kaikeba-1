{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.复习上课内容以及复现课程代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本部分，你需要复习上课内容和课程代码后，自己复现课程代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "/\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x  #gpu\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x matmul x = [[4.]]\n"
     ]
    }
   ],
   "source": [
    "x = [[2.]]\n",
    "m = tf.matmul(x,x)\n",
    "print(\"x matmul x = {}\".format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1,2],\n",
    "                 [3,4]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#Broadcasting \n",
    "b = tf.add(a,1)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 2  6]\n",
      " [12 20]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#element-wise multiplication\n",
    "print(a*b)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10 13]\n",
      " [22 29]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.matmul(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  6]\n",
      " [12 20]]\n"
     ]
    }
   ],
   "source": [
    "c = np.multiply(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "#Transfer a tensor to numpy array\n",
    "print(a.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[12.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable([[2.0]])\n",
    "with tf.GradientTape() as tape:\n",
    "    loss = w * w * w\n",
    "grad = tape.gradient(loss,w)\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train[:10000,:,:]\n",
    "y_train = y_train[:10000]\n",
    "x_test = x_test[:1000,:,:]\n",
    "y_test = y_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.cast(x_train[...,tf.newaxis]/255, tf.float32)\n",
    "x_test = tf.cast(x_test[...,tf.newaxis]/255, tf.float32)\n",
    "\n",
    "#y_train = y_train.astype('float32')\n",
    "#y_test = y_test.astype('float32')\n",
    "y_train = tf.keras.utils.to_categorical(y_train,10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方式1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model using Sequential\n",
    "\n",
    "mnist_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32,[3,3],activation='relu',\n",
    "                          input_shape=(28,28,1)),\n",
    "    tf.keras.layers.Conv2D(64,[3,3],activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128,activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10,activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_54 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnist_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                    validation_split=0.1,shuffle=True,\n",
    "                   loss = tf.keras.losses.categorical_crossentropy,\n",
    "                   metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "8000/8000 [==============================] - 3s 341us/sample - loss: 0.7692 - accuracy: 0.7571 - val_loss: 0.2866 - val_accuracy: 0.9140\n",
      "Epoch 2/20\n",
      "8000/8000 [==============================] - 2s 250us/sample - loss: 0.2599 - accuracy: 0.9241 - val_loss: 0.1852 - val_accuracy: 0.9375\n",
      "Epoch 3/20\n",
      "8000/8000 [==============================] - 2s 250us/sample - loss: 0.1652 - accuracy: 0.9528 - val_loss: 0.1372 - val_accuracy: 0.9595\n",
      "Epoch 4/20\n",
      "8000/8000 [==============================] - 2s 251us/sample - loss: 0.1218 - accuracy: 0.9632 - val_loss: 0.1181 - val_accuracy: 0.9655\n",
      "Epoch 5/20\n",
      "8000/8000 [==============================] - 2s 250us/sample - loss: 0.1019 - accuracy: 0.9675 - val_loss: 0.1141 - val_accuracy: 0.9655\n",
      "Epoch 6/20\n",
      "8000/8000 [==============================] - 2s 250us/sample - loss: 0.0755 - accuracy: 0.9761 - val_loss: 0.1047 - val_accuracy: 0.9720\n",
      "Epoch 7/20\n",
      "8000/8000 [==============================] - 2s 248us/sample - loss: 0.0698 - accuracy: 0.9770 - val_loss: 0.0964 - val_accuracy: 0.9695\n",
      "Epoch 8/20\n",
      "8000/8000 [==============================] - 2s 258us/sample - loss: 0.0637 - accuracy: 0.9803 - val_loss: 0.0928 - val_accuracy: 0.9750\n",
      "Epoch 9/20\n",
      "8000/8000 [==============================] - 2s 260us/sample - loss: 0.0577 - accuracy: 0.9810 - val_loss: 0.0953 - val_accuracy: 0.9715\n",
      "Epoch 10/20\n",
      "8000/8000 [==============================] - 2s 257us/sample - loss: 0.0515 - accuracy: 0.9831 - val_loss: 0.0841 - val_accuracy: 0.9795\n",
      "Epoch 11/20\n",
      "8000/8000 [==============================] - 2s 263us/sample - loss: 0.0391 - accuracy: 0.9865 - val_loss: 0.0944 - val_accuracy: 0.9705\n",
      "Epoch 12/20\n",
      "8000/8000 [==============================] - 2s 264us/sample - loss: 0.0354 - accuracy: 0.9890 - val_loss: 0.1053 - val_accuracy: 0.9705\n",
      "Epoch 13/20\n",
      "8000/8000 [==============================] - 2s 255us/sample - loss: 0.0443 - accuracy: 0.9835 - val_loss: 0.0870 - val_accuracy: 0.9780\n",
      "Epoch 14/20\n",
      "8000/8000 [==============================] - 2s 254us/sample - loss: 0.0282 - accuracy: 0.9911 - val_loss: 0.0906 - val_accuracy: 0.9770\n",
      "Epoch 15/20\n",
      "8000/8000 [==============================] - 2s 259us/sample - loss: 0.0260 - accuracy: 0.9915 - val_loss: 0.0941 - val_accuracy: 0.9755\n",
      "Epoch 16/20\n",
      "8000/8000 [==============================] - 2s 257us/sample - loss: 0.0238 - accuracy: 0.9918 - val_loss: 0.0922 - val_accuracy: 0.9780\n",
      "Epoch 17/20\n",
      "8000/8000 [==============================] - 2s 257us/sample - loss: 0.0219 - accuracy: 0.9934 - val_loss: 0.1077 - val_accuracy: 0.9745\n",
      "Epoch 18/20\n",
      "8000/8000 [==============================] - 2s 258us/sample - loss: 0.0275 - accuracy: 0.9906 - val_loss: 0.0846 - val_accuracy: 0.9760\n",
      "Epoch 19/20\n",
      "8000/8000 [==============================] - 2s 256us/sample - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.1104 - val_accuracy: 0.9745\n",
      "Epoch 20/20\n",
      "8000/8000 [==============================] - 2s 256us/sample - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.0936 - val_accuracy: 0.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a773e9f2e8>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_model.fit(x_train,y_train,batch_size=128,epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1000/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 129us/sample - loss: 0.0313 - accuracy: 0.9780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06101668152678758, 0.978]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 28, 28, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.7537808e-06, 1.8767276e-05, 2.8195756e-05, 3.2132788e-04,\n",
       "        2.8035001e-06, 2.4515793e-06, 1.2309952e-06, 9.9873370e-01,\n",
       "        1.2407571e-05, 8.7650545e-04]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_model.predict(x_test[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model using Model\n",
    "inputs = tf.keras.Input(shape=(28,28,1),name=\"digits\")\n",
    "conv_1 = tf.keras.layers.Conv2D(32,[3,3],activation=\"relu\")(inputs)\n",
    "conv_2 = tf.keras.layers.Conv2D(64,[3,3],activation=\"relu\")(conv_1)\n",
    "max_pool = tf.keras.layers.MaxPool2D(pool_size=(2,2))(conv_2)\n",
    "dropout_1 = tf.keras.layers.Dropout(0.25)(max_pool)\n",
    "flatten = tf.keras.layers.Flatten()(dropout_1)\n",
    "dense = tf.keras.layers.Dense(128, activation='relu')(flatten)\n",
    "dropout_2 = tf.keras.layers.Dropout(0.25)(dense)\n",
    "outputs = tf.keras.layers.Dense(10, activation='softmax')(dense)\n",
    "mnist_model_2 = tf.keras.Model(inputs=inputs,outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model using Model\n",
    "inputs = tf.keras.Input(shape=(None,None,1),name=\"digits\")\n",
    "conv_1 = tf.keras.layers.Conv2D(16,[3,3],activation=\"relu\")(inputs)\n",
    "conv_2 = tf.keras.layers.Conv2D(16,[3,3],activation=\"relu\")(conv_1)\n",
    "ave_pool = tf.keras.layers.GlobalAveragePooling2D()(conv_2)\n",
    "outputs = tf.keras.layers.Dense(10, activation='softmax')(ave_pool)\n",
    "mnist_model_2 = tf.keras.Model(inputs=inputs,outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "digits (InputLayer)          [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnist_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 3s 337us/sample - loss: 0.5769 - accuracy: 0.8381 - val_loss: 0.2763 - val_accuracy: 0.9220\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 2s 252us/sample - loss: 0.1653 - accuracy: 0.9519 - val_loss: 0.1624 - val_accuracy: 0.9510\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 2s 253us/sample - loss: 0.0936 - accuracy: 0.9715 - val_loss: 0.1331 - val_accuracy: 0.9595\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 2s 264us/sample - loss: 0.0569 - accuracy: 0.9841 - val_loss: 0.1096 - val_accuracy: 0.9635\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 2s 255us/sample - loss: 0.0397 - accuracy: 0.9870 - val_loss: 0.1104 - val_accuracy: 0.9680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a749ab19e8>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_model_2.compile(loss = tf.keras.losses.categorical_crossentropy,\n",
    "                      optimizer=tf.keras.optimizers.Adam(),\n",
    "                     metrics=[\"accuracy\"])\n",
    "mnist_model_2.fit(x_train,y_train,batch_size=128,epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USE TF2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train[:10000,:,:]\n",
    "y_train = y_train[:10000]\n",
    "x_test = x_test[:1000,:,:]\n",
    "y_test = y_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "(tf.cast(x_train[...,tf.newaxis]/255, tf.float32),\n",
    " tf.cast(y_train,tf.int64)))\n",
    "dataset = dataset.shuffle(1000).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 finishted\n",
      "Epoch 1 finishted\n",
      "Epoch 2 finishted\n",
      "Epoch 3 finishted\n",
      "Epoch 4 finishted\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    \n",
    "    for (batch, (images,labels)) in enumerate (dataset):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            logits = mnist_model(images,training=True)\n",
    "            loss_value = loss(labels,logits)\n",
    "            \n",
    "        grads = tape.gradient(loss_value,mnist_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads,mnist_model.trainable_variables))\n",
    "        \n",
    "    print(\"Epoch {} finishted\".format(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.回答以下理论题目?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Compared to FNN, what is the biggest advantage of CNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和FNN相比，CNN使用了卷积核。这个的效果就是参数共享。参数共享带来两个好处：  \n",
    "1、与FNN相比，显著减少了总的参数数量；  \n",
    "2、共享的卷积核实现了平移不变性，即无论目标在图片中的哪个位置，卷积核都能扫描到它。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Suppose your input is a 100 by 100 gray image, and you use a convolutional layer with 50 filters that are each 5x5. How many parameters does this hidden layer have (including the bias parameters)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总的参数数量为： (5X5+1)X50=1300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What are \"local invariant\" and \"parameter sharing\" ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“local invariant”指的是局部特征不变化。每个卷积核表示一个特征，这个卷积核扫描过图片的每个位置，任何局部图像能匹配这个卷积核特征，都会被发现。所以CNN训练出来的模型，不会依赖这个特征在图片的位置。  \n",
    "“parameter sharing”是参数共享，这个是相对于普通的全连接网络来说的。全连接网络，每个参数只对对应的上一层输入使用一次，所以参数非常多。卷积核的话，同一个卷积核会对上一层的所有数据都计算一遍，一个卷积核在计算时会被使用多次，被“共享”使用了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why we use batch normalization ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "常见的激活函数，比如sigmoid，relu，tanh等，都是在0附近梯度较大，在远离0的范围时，梯度趋向于0，这样在进行梯度下降计算时效果不好。所以就需要在使用激活函数前对上一层的输出数据做处理，转换成为均值为0方差为1的数据，这样就可以落在激活函数梯度较大的范围，比较容易收敛。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What problem does dropout try to solve ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropout是为了解决过拟合。dropout随机忽略部分参数不参与计算，就可以避免对特定的w值过分依赖，以此减少过拟合的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.  Is the following statement correct and why ? \"Because pooling layers do not have parameters, they do not affect  the backpropagation(derivatives) calculation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "错误。池化层虽然没有可训练的参数，但还是有计算的。梯度反向传播时，还是需要将梯度透过池化层传播到前面。总的思路是保持梯度之和不变：mean pooling是把梯度平均传递到前一层；max pooling是把梯度传播到max值对应的元素，其余元素得到的梯度为0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 实践题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 In the first session of the practical part, you will implement an image classification model using any deep learning libraries that you are familiar with,  which means, except for tensorflow and keras, you can also use pytorch/caffe/... .  The dataset used in this session is the cifar10 which contains 50000 color (RGB) images, each with size 32x32x3.  All 50000 images are classified into ten categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\myx\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # -1使用cpu，0就是使用gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "y_train = np.eye(10)[y_train.squeeze()]\n",
    "y_test = np.eye(10)[y_test.squeeze()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It is your time to build your model. Try your best to build a model with good performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Dropout, Activation, Conv2D, MaxPool2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "# from keras.callbacks import TensorBoard\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 第一个卷积层，32个卷积核，大小５x5，卷积模式SAME,激活函数relu,输入张量的大小\n",
    "model.add(Conv2D(filters= 64, kernel_size=(3,3), padding='Same', activation='tanh',input_shape=(32,32,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters= 128, kernel_size=(3,3), padding='Same', activation='tanh'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters= 128, kernel_size=(3,3), padding='Same', activation='tanh'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "# model.add(Conv2D(filters= 16, kernel_size=(3,3), padding='Same', activation='relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.2))\n",
    "# 全连接层,展开操作，\n",
    "model.add(Flatten())\n",
    "# 添加隐藏层神经元的数量和激活函数\n",
    "model.add(Dense(128, activation='tanh'))    \n",
    "model.add(Dropout(0.25))\n",
    "# 输出层\n",
    "model.add(Dense(10, activation='softmax'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "            optimizer='Adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 486,794\n",
      "Trainable params: 486,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "40000/40000 [==============================] - 23s 575us/step - loss: 1.5215 - acc: 0.4568 - val_loss: 1.1595 - val_acc: 0.5909\n",
      "Epoch 2/50\n",
      "40000/40000 [==============================] - 22s 552us/step - loss: 1.1433 - acc: 0.5988 - val_loss: 1.0150 - val_acc: 0.6455\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 22s 558us/step - loss: 1.0300 - acc: 0.6416 - val_loss: 0.9316 - val_acc: 0.6755\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 23s 563us/step - loss: 0.9442 - acc: 0.6707 - val_loss: 0.9165 - val_acc: 0.6817\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 23s 563us/step - loss: 0.9037 - acc: 0.6846 - val_loss: 0.8925 - val_acc: 0.6916\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 22s 562us/step - loss: 0.8436 - acc: 0.7078 - val_loss: 0.8842 - val_acc: 0.6921\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 23s 564us/step - loss: 0.8083 - acc: 0.7228 - val_loss: 0.8558 - val_acc: 0.7133\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 23s 565us/step - loss: 0.7769 - acc: 0.7286 - val_loss: 0.7978 - val_acc: 0.7271\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 25s 616us/step - loss: 0.7526 - acc: 0.7367 - val_loss: 0.8053 - val_acc: 0.7222\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 22s 561us/step - loss: 0.7215 - acc: 0.7507 - val_loss: 0.7842 - val_acc: 0.7335\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 23s 578us/step - loss: 0.7085 - acc: 0.7518 - val_loss: 0.8038 - val_acc: 0.7206\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 23s 573us/step - loss: 0.6933 - acc: 0.7575 - val_loss: 0.7840 - val_acc: 0.7370\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 23s 573us/step - loss: 0.6706 - acc: 0.7651 - val_loss: 0.7678 - val_acc: 0.7420\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 23s 566us/step - loss: 0.6557 - acc: 0.7700 - val_loss: 0.7972 - val_acc: 0.7339\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 23s 565us/step - loss: 0.6391 - acc: 0.7751 - val_loss: 0.7952 - val_acc: 0.7340\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 23s 567us/step - loss: 0.6335 - acc: 0.7786 - val_loss: 0.7545 - val_acc: 0.7491\n",
      "Epoch 17/50\n",
      "40000/40000 [==============================] - 23s 566us/step - loss: 0.6165 - acc: 0.7824 - val_loss: 0.8194 - val_acc: 0.7312\n",
      "Epoch 18/50\n",
      "40000/40000 [==============================] - 23s 566us/step - loss: 0.6073 - acc: 0.7858 - val_loss: 0.7557 - val_acc: 0.7470\n",
      "Epoch 19/50\n",
      "40000/40000 [==============================] - 23s 566us/step - loss: 0.6067 - acc: 0.7861 - val_loss: 0.8633 - val_acc: 0.7110\n",
      "Epoch 20/50\n",
      "40000/40000 [==============================] - 23s 566us/step - loss: 0.5954 - acc: 0.7907 - val_loss: 0.7723 - val_acc: 0.7391\n",
      "Epoch 21/50\n",
      "40000/40000 [==============================] - 23s 566us/step - loss: 0.5942 - acc: 0.7890 - val_loss: 0.7778 - val_acc: 0.7387\n",
      "Epoch 22/50\n",
      "40000/40000 [==============================] - 23s 574us/step - loss: 0.5810 - acc: 0.7934 - val_loss: 0.7527 - val_acc: 0.7516\n",
      "Epoch 23/50\n",
      "40000/40000 [==============================] - 23s 567us/step - loss: 0.5796 - acc: 0.7963 - val_loss: 0.7556 - val_acc: 0.7497\n",
      "Epoch 24/50\n",
      "40000/40000 [==============================] - 23s 569us/step - loss: 0.5693 - acc: 0.7982 - val_loss: 0.7627 - val_acc: 0.7489\n",
      "Epoch 25/50\n",
      "40000/40000 [==============================] - 23s 567us/step - loss: 0.5602 - acc: 0.8019 - val_loss: 0.7531 - val_acc: 0.7538\n",
      "Epoch 26/50\n",
      "40000/40000 [==============================] - 23s 567us/step - loss: 0.5609 - acc: 0.8022 - val_loss: 0.7759 - val_acc: 0.7437\n",
      "Epoch 27/50\n",
      "40000/40000 [==============================] - 23s 576us/step - loss: 0.5529 - acc: 0.8047 - val_loss: 0.7595 - val_acc: 0.7494\n",
      "Epoch 28/50\n",
      "40000/40000 [==============================] - 23s 567us/step - loss: 0.5538 - acc: 0.8045 - val_loss: 0.7626 - val_acc: 0.7502\n",
      "Epoch 29/50\n",
      "40000/40000 [==============================] - 23s 567us/step - loss: 0.5556 - acc: 0.8035 - val_loss: 0.7629 - val_acc: 0.7528\n",
      "Epoch 30/50\n",
      "40000/40000 [==============================] - 23s 567us/step - loss: 0.5502 - acc: 0.8063 - val_loss: 0.7794 - val_acc: 0.7484\n",
      "Epoch 31/50\n",
      "40000/40000 [==============================] - 23s 569us/step - loss: 0.5514 - acc: 0.8062 - val_loss: 0.7627 - val_acc: 0.7518\n",
      "Epoch 32/50\n",
      "40000/40000 [==============================] - 23s 567us/step - loss: 0.5354 - acc: 0.8102 - val_loss: 0.7670 - val_acc: 0.7518\n",
      "Epoch 33/50\n",
      "40000/40000 [==============================] - 23s 568us/step - loss: 0.5429 - acc: 0.8082 - val_loss: 0.7722 - val_acc: 0.7494\n",
      "Epoch 34/50\n",
      "40000/40000 [==============================] - 23s 571us/step - loss: 0.5349 - acc: 0.8124 - val_loss: 0.7841 - val_acc: 0.7498\n",
      "Epoch 35/50\n",
      "40000/40000 [==============================] - 23s 569us/step - loss: 0.5270 - acc: 0.8124 - val_loss: 0.7955 - val_acc: 0.7472\n",
      "Epoch 36/50\n",
      "40000/40000 [==============================] - 23s 570us/step - loss: 0.5350 - acc: 0.8127 - val_loss: 0.7735 - val_acc: 0.7509\n",
      "Epoch 37/50\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 0.5221 - acc: 0.8151 - val_loss: 0.7681 - val_acc: 0.7541\n",
      "Epoch 38/50\n",
      "40000/40000 [==============================] - 23s 575us/step - loss: 0.5271 - acc: 0.8132 - val_loss: 0.7496 - val_acc: 0.7601\n",
      "Epoch 39/50\n",
      "40000/40000 [==============================] - 23s 566us/step - loss: 0.5262 - acc: 0.8129 - val_loss: 0.7755 - val_acc: 0.7512\n",
      "Epoch 40/50\n",
      "40000/40000 [==============================] - 23s 568us/step - loss: 0.5244 - acc: 0.8154 - val_loss: 0.7625 - val_acc: 0.7544\n",
      "Epoch 41/50\n",
      "40000/40000 [==============================] - 23s 585us/step - loss: 0.5090 - acc: 0.8189 - val_loss: 0.7455 - val_acc: 0.7585\n",
      "Epoch 42/50\n",
      "40000/40000 [==============================] - 22s 556us/step - loss: 0.5134 - acc: 0.8185 - val_loss: 0.7620 - val_acc: 0.7532\n",
      "Epoch 43/50\n",
      "40000/40000 [==============================] - 23s 574us/step - loss: 0.5199 - acc: 0.8150 - val_loss: 0.7621 - val_acc: 0.7548\n",
      "Epoch 44/50\n",
      "40000/40000 [==============================] - 23s 565us/step - loss: 0.5123 - acc: 0.8187 - val_loss: 0.7551 - val_acc: 0.7576\n",
      "Epoch 45/50\n",
      "40000/40000 [==============================] - 23s 571us/step - loss: 0.5149 - acc: 0.8181 - val_loss: 0.7682 - val_acc: 0.7483\n",
      "Epoch 46/50\n",
      "40000/40000 [==============================] - 23s 569us/step - loss: 0.5147 - acc: 0.8169 - val_loss: 0.7584 - val_acc: 0.7549\n",
      "Epoch 47/50\n",
      "40000/40000 [==============================] - 23s 568us/step - loss: 0.5200 - acc: 0.8173 - val_loss: 0.7721 - val_acc: 0.7538\n",
      "Epoch 48/50\n",
      "40000/40000 [==============================] - 23s 569us/step - loss: 0.5024 - acc: 0.8221 - val_loss: 0.7903 - val_acc: 0.7500\n",
      "Epoch 49/50\n",
      "40000/40000 [==============================] - 23s 573us/step - loss: 0.5148 - acc: 0.8163 - val_loss: 0.7559 - val_acc: 0.7631\n",
      "Epoch 50/50\n",
      "40000/40000 [==============================] - 23s 570us/step - loss: 0.5041 - acc: 0.8198 - val_loss: 0.7508 - val_acc: 0.7602\n"
     ]
    }
   ],
   "source": [
    "train_history=model.fit(x=x_train,\n",
    "                       y=y_train,\n",
    "                       validation_split=0.2,\n",
    "                       epochs=50,\n",
    "                       batch_size=100,\n",
    "                       shuffle=True,\n",
    "                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history.history['loss'], label='loss')\n",
    "plt.plot(train_history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_history.history['acc'], label='accuracy')\n",
    "plt.plot(train_history.history['val_acc'], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 231us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7563554677009583, 0.7534]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Optional "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Do you want to build a CNN from scratch ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this optianl part, you will build a cnn network step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 Implement a convolution step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hints: Numpy.sum function might be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(a_prev_slice,W,b):\n",
    "    '''\n",
    "    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n",
    "    of the previous layer.\n",
    "    Arguments:\n",
    "    a_prev_slice: slice of input data (shape=(f,f,n_C_prev))\n",
    "    W: Weight parameters contained in a window. (shape = (f,f,n_C_prev))\n",
    "    b: Bias parameters contained in a window. (shape=(1,1,1))\n",
    "    \n",
    "    Reutrns:\n",
    "    \n",
    "    Z: a scalar value, the result of convolving the sliding window (W, b) on a slice x of the input data \n",
    "    '''\n",
    "    # Element-wise product\n",
    "    s = a_prev_slice * W\n",
    "    \n",
    "    # Sum over s  \n",
    "    Z = np.sum(s)\n",
    "    \n",
    "    # Add bias b to z.\n",
    "    Z += np.squeeze(b)\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = -6.999089450680221\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "a_slice_prev = np.random.randn(4, 4, 3)\n",
    "W = np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "\n",
    "Z = conv_single_step(a_slice_prev, W, b)\n",
    "print(\"Z =\", Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code above to test your code. If your c\n",
    "ode is correct, you should be able to get the output shown as below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            Z\n",
    "        </td>\n",
    "        <td>\n",
    "            -6.99908945068\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hints: Numpy.pad function might be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, \n",
    "    as illustrated in Figure 1.\n",
    "    \n",
    "    Argument:\n",
    "    X: python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
    "    pad: integer, amount of padding around each image on vertical and horizontal dimensions\n",
    "    \n",
    "    Returns:\n",
    "    X_pad: padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    X_pad = np.zeros((X.shape[0], X.shape[1] + 2*pad, X.shape[2] + 2*pad, X.shape[3]))\n",
    "    X_pad[:, pad:X.shape[1] + pad, pad:X.shape[2] + pad, :] = X\n",
    "    \n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =\n",
      " (4, 3, 3, 2)\n",
      "x_pad.shape =\n",
      " (4, 7, 7, 2)\n",
      "x[1,1] =\n",
      " [[ 0.90085595 -0.68372786]\n",
      " [-0.12289023 -0.93576943]\n",
      " [-0.26788808  0.53035547]]\n",
      "x_pad[1,1] =\n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(4, 3, 3, 2)\n",
    "x_pad = zero_pad(x, 2)\n",
    "print (\"x.shape =\\n\", x.shape)\n",
    "print (\"x_pad.shape =\\n\", x_pad.shape)\n",
    "print (\"x[1,1] =\\n\", x[1,1])\n",
    "print (\"x_pad[1,1] =\\n\", x_pad[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code above to test your code. If your code is correct, you should be able to get the output shown as below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "x.shape =\n",
    " (4, 3, 3, 2)\n",
    "x_pad.shape =\n",
    " (4, 7, 7, 2)\n",
    "x[1,1] =\n",
    " [[ 0.90085595 -0.68372786]\n",
    " [-0.12289023 -0.93576943]\n",
    " [-0.26788808  0.53035547]]\n",
    "x_pad[1,1] =\n",
    " [[ 0.  0.]\n",
    " [ 0.  0.]\n",
    " [ 0.  0.]\n",
    " [ 0.  0.]\n",
    " [ 0.  0.]\n",
    " [ 0.  0.]\n",
    " [ 0.  0.]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 Implement a forward propagation in CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hints: The formulas to calculate the output shapes are :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ n_H = \\lfloor \\frac{n_{H_{prev}} - f + 2 \\times pad}{stride} \\rfloor +1 $$\n",
    "$$ n_W = \\lfloor \\frac{n_{W_{prev}} - f + 2 \\times pad}{stride} \\rfloor +1 $$\n",
    "$$ n_C = \\text{number of filters used in the convolution}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for a convolution function\n",
    "    \n",
    "    Arguments:\n",
    "    A_prev: output activations of the previous layer, \n",
    "        numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    W: Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
    "    b: Biases, numpy array of shape (1, 1, 1, n_C)\n",
    "    hparameters: python dictionary containing \"stride\" and \"pad\"\n",
    "        \n",
    "    Returns:\n",
    "    Z: conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache: cache of values needed for the conv_backward() function\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get dimensions from A_prev's shape  \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Get dimensions from W's shape \n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # Get information from \"hparameters\" \n",
    "    stride = hparameters['stride']\n",
    "    pad = hparameters['pad']\n",
    "    \n",
    "    # Compute the dimensions of the CONV output volume using the formula given above. \n",
    "    # Hint: use int() to apply the 'floor' operation. \n",
    "    n_H = int((n_H_prev + 2*pad - f) / stride + 1)\n",
    "    n_W = int((n_W_prev + 2*pad - f) / stride + 1)\n",
    "    \n",
    "    # Initialize the output volume Z with zeros. \n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Create A_prev_pad by padding A_prev\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    \n",
    "    for i in range(m):                  # loop over the batch of training examples\n",
    "        a_prev_pad = A_prev_pad         # Select ith training example's padded activation\n",
    "        for h in range(n_H):            # loop over vertical axis of the output volume\n",
    "            # Find the vertical start and end of the current \"slice\" \n",
    "            vert_start = stride * h\n",
    "            vert_end = stride * h + f\n",
    "            \n",
    "            for w in range(n_W):        # loop over horizontal axis of the output volume\n",
    "                # Find the horizontal start and end of the current \"slice\"\n",
    "                horiz_start = stride * w\n",
    "                horiz_end = stride * w + f\n",
    "                \n",
    "                for c in range(n_C):    # loop over channels (= #filters) of the output volume\n",
    "                                        \n",
    "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). \n",
    "                    a_slice_prev = a_prev_pad[i, vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    \n",
    "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. \n",
    "                    weights = W[:,:,:,c]\n",
    "                    biases = b[:,:,:,c]\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, weights, biases)\n",
    "                                        \n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Save information in \"cache\" for the backprop\n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z's mean =\n",
      " 0.6923608807576933\n",
      "Z[3,2,1] =\n",
      " [-1.28912231  2.27650251  6.61941931  0.95527176  8.25132576  2.31329639\n",
      " 13.00689405  2.34576051]\n",
      "cache_conv[0][1][2][3] =\n",
      " [-1.1191154   1.9560789  -0.3264995  -1.34267579]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(10,5,7,4)\n",
    "W = np.random.randn(3,3,4,8)\n",
    "b = np.random.randn(1,1,1,8)\n",
    "hparameters = {\"pad\" : 1,\n",
    "               \"stride\": 2}\n",
    "\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
    "print(\"Z's mean =\\n\", np.mean(Z))\n",
    "print(\"Z[3,2,1] =\\n\", Z[3,2,1])\n",
    "print(\"cache_conv[0][1][2][3] =\\n\", cache_conv[0][1][2][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code above to test your code. If your code is correct, you should be able to get the output shown as below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Z's mean =\n",
    " 0.692360880758\n",
    "Z[3,2,1] =\n",
    " [ -1.28912231   2.27650251   6.61941931   0.95527176   8.25132576\n",
    "   2.31329639  13.00689405   2.34576051]\n",
    "cache_conv[0][1][2][3] = [-1.1191154   1.9560789  -0.3264995  -1.34267579]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4 Pooling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hints: As there\\'s no padding, the formulas binding the output shape of the pooling to the input shape is:\n",
    "\n",
    "$$ n_H = \\lfloor \\frac{n_{H_{prev}} - f}{stride} \\rfloor +1 $$\n",
    "\n",
    "$$ n_W = \\lfloor \\frac{n_{W_{prev}} - f}{stride} \\rfloor +1 $$\n",
    "\n",
    "$$ n_C = n_{C_{prev}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
    "    \"\"\"\n",
    "    Implements the forward pass of the pooling layer\n",
    "    \n",
    "    Arguments:\n",
    "    A_prev: Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    hparameters: python dictionary containing \"f\" and \"stride\"\n",
    "    mode: the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
    "    \n",
    "    Returns:\n",
    "    A: output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache: cache used in the backward pass of the pooling layer, contains the input and hparameters \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get dimensions from the input shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Get hyperparameters from \"hparameters\"\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    \n",
    "    # Define the dimensions of the output\n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C = n_C_prev\n",
    "    \n",
    "    # Initialize output matrix A\n",
    "    A = np.zeros((m, n_H, n_W, n_C))              \n",
    "    \n",
    "    for i in range(m):                         # loop over the training examples\n",
    "        for h in range(n_H):                     # loop on the vertical axis of the output volume\n",
    "            # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
    "            vert_start = stride * h\n",
    "            vert_end = stride * h + f\n",
    "            \n",
    "            for w in range(n_W):                 # loop on the horizontal axis of the output volume\n",
    "                # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
    "                horiz_start = stride * w\n",
    "                horiz_end = stride * w + f\n",
    "                \n",
    "                for c in range (n_C):            # loop over the channels of the output volume\n",
    "                    \n",
    "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)\n",
    "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                    \n",
    "                    # Compute the pooling operation on the slice. \n",
    "                    # Use an if statement to differentiate the modes. \n",
    "                    # Use np.max and np.mean.\n",
    "                    if mode == \"max\":\n",
    "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
    "                    elif mode == \"average\":\n",
    "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
    "    \n",
    "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
    "    cache = (A_prev, hparameters)\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(A.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "A.shape = (2, 3, 3, 3)\n",
      "A =\n",
      " [[[[1.74481176 0.90159072 1.65980218]\n",
      "   [1.74481176 1.46210794 1.65980218]\n",
      "   [1.74481176 1.6924546  1.65980218]]\n",
      "\n",
      "  [[1.14472371 0.90159072 2.10025514]\n",
      "   [1.14472371 0.90159072 1.65980218]\n",
      "   [1.14472371 1.6924546  1.65980218]]\n",
      "\n",
      "  [[1.13162939 1.51981682 2.18557541]\n",
      "   [1.13162939 1.51981682 2.18557541]\n",
      "   [1.13162939 1.6924546  2.18557541]]]\n",
      "\n",
      "\n",
      " [[[1.19891788 0.84616065 0.82797464]\n",
      "   [0.69803203 0.84616065 1.2245077 ]\n",
      "   [0.69803203 1.12141771 1.2245077 ]]\n",
      "\n",
      "  [[1.96710175 0.84616065 1.27375593]\n",
      "   [1.96710175 0.84616065 1.23616403]\n",
      "   [1.62765075 1.12141771 1.2245077 ]]\n",
      "\n",
      "  [[1.96710175 0.86888616 1.27375593]\n",
      "   [1.96710175 0.86888616 1.23616403]\n",
      "   [1.62765075 1.12141771 0.79280687]]]]\n",
      "\n",
      "mode = average\n",
      "A.shape = (2, 3, 3, 3)\n",
      "A =\n",
      " [[[[-3.01046719e-02 -3.24021315e-03 -3.36298859e-01]\n",
      "   [ 1.43310483e-01  1.93146751e-01 -4.44905196e-01]\n",
      "   [ 1.28934436e-01  2.22428468e-01  1.25067597e-01]]\n",
      "\n",
      "  [[-3.81801899e-01  1.59993515e-02  1.70562706e-01]\n",
      "   [ 4.73707165e-02  2.59244658e-02  9.20338402e-02]\n",
      "   [ 3.97048605e-02  1.57189094e-01  3.45302489e-01]]\n",
      "\n",
      "  [[-3.82680519e-01  2.32579951e-01  6.25997903e-01]\n",
      "   [-2.47157416e-01 -3.48524998e-04  3.50539717e-01]\n",
      "   [-9.52551510e-02  2.68511000e-01  4.66056368e-01]]]\n",
      "\n",
      "\n",
      " [[[-1.73134159e-01  3.23771981e-01 -3.43175716e-01]\n",
      "   [ 3.80634669e-02  7.26706274e-02 -2.30268958e-01]\n",
      "   [ 2.03009393e-02  1.41414785e-01 -1.23158476e-02]]\n",
      "\n",
      "  [[ 4.44976963e-01 -2.61694592e-03 -3.10403073e-01]\n",
      "   [ 5.08114737e-01 -2.34937338e-01 -2.39611830e-01]\n",
      "   [ 1.18726772e-01  1.72552294e-01 -2.21121966e-01]]\n",
      "\n",
      "  [[ 4.29449255e-01  8.44699612e-02 -2.72909051e-01]\n",
      "   [ 6.76351685e-01 -1.20138225e-01 -2.44076712e-01]\n",
      "   [ 1.50774518e-01  2.89111751e-01  1.23238536e-03]]]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 5, 5, 3)\n",
    "hparameters = {\"stride\" : 1, \"f\": 3}\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "print(\"mode = max\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A =\\n\", A)\n",
    "print()\n",
    "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A =\\n\", A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code above to test your code. If your code is correct, you should be able to get the output shown as below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "mode = max\n",
    "A.shape = (2, 3, 3, 3)\n",
    "A =\n",
    " [[[[ 1.74481176  0.90159072  1.65980218]\n",
    "   [ 1.74481176  1.46210794  1.65980218]\n",
    "   [ 1.74481176  1.6924546   1.65980218]]\n",
    "\n",
    "  [[ 1.14472371  0.90159072  2.10025514]\n",
    "   [ 1.14472371  0.90159072  1.65980218]\n",
    "   [ 1.14472371  1.6924546   1.65980218]]\n",
    "\n",
    "  [[ 1.13162939  1.51981682  2.18557541]\n",
    "   [ 1.13162939  1.51981682  2.18557541]\n",
    "   [ 1.13162939  1.6924546   2.18557541]]]\n",
    "\n",
    "\n",
    " [[[ 1.19891788  0.84616065  0.82797464]\n",
    "   [ 0.69803203  0.84616065  1.2245077 ]\n",
    "   [ 0.69803203  1.12141771  1.2245077 ]]\n",
    "\n",
    "  [[ 1.96710175  0.84616065  1.27375593]\n",
    "   [ 1.96710175  0.84616065  1.23616403]\n",
    "   [ 1.62765075  1.12141771  1.2245077 ]]\n",
    "\n",
    "  [[ 1.96710175  0.86888616  1.27375593]\n",
    "   [ 1.96710175  0.86888616  1.23616403]\n",
    "   [ 1.62765075  1.12141771  0.79280687]]]]\n",
    "\n",
    "mode = average\n",
    "A.shape = (2, 3, 3, 3)\n",
    "A =\n",
    " [[[[ -3.01046719e-02  -3.24021315e-03  -3.36298859e-01]\n",
    "   [  1.43310483e-01   1.93146751e-01  -4.44905196e-01]\n",
    "   [  1.28934436e-01   2.22428468e-01   1.25067597e-01]]\n",
    "\n",
    "  [[ -3.81801899e-01   1.59993515e-02   1.70562706e-01]\n",
    "   [  4.73707165e-02   2.59244658e-02   9.20338402e-02]\n",
    "   [  3.97048605e-02   1.57189094e-01   3.45302489e-01]]\n",
    "\n",
    "  [[ -3.82680519e-01   2.32579951e-01   6.25997903e-01]\n",
    "   [ -2.47157416e-01  -3.48524998e-04   3.50539717e-01]\n",
    "   [ -9.52551510e-02   2.68511000e-01   4.66056368e-01]]]\n",
    "\n",
    "\n",
    " [[[ -1.73134159e-01   3.23771981e-01  -3.43175716e-01]\n",
    "   [  3.80634669e-02   7.26706274e-02  -2.30268958e-01]\n",
    "   [  2.03009393e-02   1.41414785e-01  -1.23158476e-02]]\n",
    "\n",
    "  [[  4.44976963e-01  -2.61694592e-03  -3.10403073e-01]\n",
    "   [  5.08114737e-01  -2.34937338e-01  -2.39611830e-01]\n",
    "   [  1.18726772e-01   1.72552294e-01  -2.21121966e-01]]\n",
    "\n",
    "  [[  4.29449255e-01   8.44699612e-02  -2.72909051e-01]\n",
    "   [  6.76351685e-01  -1.20138225e-01  -2.44076712e-01]\n",
    "   [  1.50774518e-01   2.89111751e-01   1.23238536e-03]]]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Congratulations! You hanve finished the assignment 6.  You now understand how convolutional neural networks work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
